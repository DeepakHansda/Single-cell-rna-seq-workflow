like many other "seq" analysis single cell rna-seq (ScRNA-seq) analysis also begins with a quality check on the initial data. Low quality libraries (cell) in a ScRNA-seq can srise from a veriety of sources.
Such as,
1. Cell damage during dissociation.
2. Failure in library preparation (inefficient reverse transcription or PCR amplification)
3. Inclusion of libraries with "low count" e.g., lot of cells with few expressed genes and high ```mitochondial``` (mt) and ```spike-in``` proportions.

We can apply few important quality metrices to indentify ```low quality cells```. Namely,
1. Library size (sum of all features [genes] in a cell). If it is low then it is considered a bad library.
2. Numbers of expressed features [# of genes with non-zero count]. If it is low then it is considered a bad library.
3. Proportion of reads mapped to ```spiked-in transcripts```. Since we start with equal numbers of transcripts added to each cell, any enrichment in ```spiked in transcripts``` shows that endogeneous genes has been lost and may results in poor library.
4. In the absense of ```spiked in transcripts``` proportion of reads mapped to ```mitochondrial``` genome can be an indication of the quality of a library. High proportion of reads mapped to ```mitochondrial``` genome indicates the low quality of library.

So above mentioned are the metrices we usually apply to assess the quality of a library and to calculate the QC metrices we use ```perCellQCMetrics()``` function from **scuttle** package.

But first we need to obtain some scRNA data to begin with. We will use data set from Lun et al. (2017) which is part of **scRNAseq** package

```r
library(scRNAseq)
sce.416b <- LunSpikeInData(which="416b") 
sce.416b$block <- factor(sce.416b$block)
```

We can look at the contents of the ```SingleCellExperiment``` object ```sce.416b```  

```r
> sce.416b
class: SingleCellExperiment 
dim: 46604 192 
metadata(0):
assays(1): counts
rownames(46604): ENSMUSG00000102693 ENSMUSG00000064842 ...
  ENSMUSG00000095742 CBFB-MYH11-mcherry
rowData names(1): Length
colnames(192): SLX-9555.N701_S502.C89V9ANXX.s_1.r_1
  SLX-9555.N701_S503.C89V9ANXX.s_1.r_1 ...
  SLX-11312.N712_S508.H5H5YBBXX.s_8.r_1
  SLX-11312.N712_S517.H5H5YBBXX.s_8.r_1
colData names(9): Source Name cell line ... spike-in addition block
reducedDimNames(0):
mainExpName: endogenous
altExpNames(2): ERCC SIRV
```



### Identifying mitochondrial transcripts in SCE
```r
location <- rowRanges(sce.416b)
is.mito <- any(seqnames(location)=="MT")

library(scuttle)
df <- perCellQCMetrics(sce.416b, subsets=list(Mito=is.mito))
summary(df$sum)
```
`rowRanges()` returns _GRanges_ or _GRangesList_ object which looks something like this,

|seqnames|ranges|strand|
|--------|------|------|
|1|3037253-3074323| + |
|MT| 3107475-3117335 | +|
|1| 4145874-4178890|- |
|3| 5439756-5440675| +|
|MT| 3278401-3293951| +|

**Explanation**

So _location_ is a _GRanges_ object. `any(seqnames(location)=="MT")` returns a logical vector with `TRUE` for any feature (gene) that has  `MT` annotation in _seqnames_ and `FALSE` for every other features in the _GRanges_ object _location_. Resultant _is.mito_
 is a logical vector with every transcript annotated as `TRUE` or `FALSE` depending on whether the transcript belongs to the mitochondrial genome or not.
 
 ```r
  > head(is.mito)
ENSMUSG00000102693 ENSMUSG00000064842 ENSMUSG00000051951 ENSMUSG00000102851 
             FALSE              FALSE              FALSE              FALSE 
ENSMUSG00000103377 ENSMUSG00000104017 
             FALSE              FALSE 
```
 It will conserve the length of rows in SCE object `416b` meaning length of logical vector `is.mito` is same as the \# of entries in _seqnames_ column in `location` which in turn is same as the \# of rows (transcripts) in `416b` object. 
 
 **End of explanation**

### Calculating QC metrics

For each cell we can calculate QC metrics using ```perCellQCMetrics()``` from **scuttle** package. This function gives out a DataFrame where rows represent\ cells (it can be noted here that cells makes columns in SCE objects) and column represents few QC metrices.
These are,\
**sum** column contains total sum of all genes.\
**detected** column contains number of expressed genes (i.e., all non-zero expressed genes).\
**subset_mito_percent** column contains percent of reads mapped to ```mt``` transcripts.\
**altexps_ERCC_percent** column contains percentage of reads mapped to ERCC transcripts. etc.

```r
library(scuttle)
df <- perCellQCMetrics(sce.416b, subsets=list(Mito=is.mito))
summary(df$sum)
```
**Explanation**

 `df` is a DataFrame object with cells as its rows and QC metrices as its column. For breviety we have taken only 5 rows and 3 columns.
 
 ```r
 > df[1:5, 1:3]
DataFrame with 5 rows and 3 columns
                                           sum  detected subsets_Mito_sum
                                     <numeric> <numeric>        <numeric>
SLX-9555.N701_S502.C89V9ANXX.s_1.r_1    865936      7618            78790
SLX-9555.N701_S503.C89V9ANXX.s_1.r_1   1076277      7521            98613
SLX-9555.N701_S504.C89V9ANXX.s_1.r_1   1180138      8306           100341
SLX-9555.N701_S505.C89V9ANXX.s_1.r_1   1342593      8143           104882
SLX-9555.N701_S506.C89V9ANXX.s_1.r_1   1668311      7154           129559
```
We can look at the summary statistics of various metrices by using `summary()` function.

```r
> summary(df$sum)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  27084  856350 1111252 1165865 1328301 4398883 
  ```
```r
> summary(df$detected)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   5609    7502    8341    8397    9208   11380
```
```r
> summary(df$subsets_Mito_detected)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  14.00   20.00   22.00   22.34   24.00   29.00
  ```
  **End of explanation**
  
  There is another function `addPerCellQCMetrics()` from **scuttle** package which compute per cell QC statistics and append it to `colData` of the `SingleCellExperiment` object. Benifit being that it allows us to retain all the relevent information in the `SingleCellExperiment` itself, so that if we need some kind of information down the line we can easily get it.
 ```r
 > sce.416b <- addPerCellQCMetrics(sce.416b, subsets=list(Mito=is.mito))
 ```
  All these QC assessment works under a key assumption that the QC metrics are independent of the biological state of each cell. Poor values (e.g., low library sizes, high mitochondrial proportions) are presumed to be driven by technical factors rather than biological processes, meaning that the subsequent removal of cells will not misrepresent the biology in downstream analyses. Needless to say the a major violations of this assumption would potentially result in the loss of cell types that have, say, systematically low RNA content or high numbers of mitochondria. 
  
  ### Identifying low quality cells
  **With fixed threshold**
  
  It is simplest of the approaches to identify the low quality cells as we tend to distinguish a good cell from a bad one with some pre-determined QC metrics cutoff. say for example, we take  the cell as of low quality if the `sum` for it is less than 100000; number of genes expressed is less than 5000; have `spike in` proportion more than 10 %; have mitochondrial proprtion more than 10 %.
  
  
  ```r
  > qc.lib <- df$sum < 1e5
> qc.nexprs <- df$detected < 5e3
> qc.spike <- df$altexps_ERCC_percent > 10
> qc.mito <- df$subsets_Mito_percent > 10
> discard <- qc.lib | qc.nexprs | qc.spike | qc.mito
```

**Explanation**

`qc.lib` and `qc.nexprs` are the `logical` vectors indicating if the cell contains less than the cut-off QC metrics. `qc.lib` contains `TRUE` for the cell which contains less than 100000 transcripts, and `FALSE` otherwise. Similar arguments can be made for `qc.nexprs` , `qc.spike` , and `qc.mito`. 
`discard` contains all such cells which have `TRUE` status in any of the above QC metrices logical vectors.

**End of explanation**

**Summarize the number of cells removed for each reason**.

```r
> discard_summary <- DataFrame(LibSize=sum(qc.lib), NExprs=sum(qc.nexprs),
+           SpikeProp=sum(qc.spike), MitoProp=sum(qc.mito), Total=sum(discard))
> discard_summary
DataFrame with 1 row and 5 columns
    LibSize    NExprs SpikeProp  MitoProp     Total
  <integer> <integer> <integer> <integer> <integer>
1         3         0        19        14        33
```

While this strategy looks deceptively simple one has to note that the ability to determine a pre-determined QC metrics cut off come with a lot of biological and experimental experiences. It may differ from one biological system to another, from one protocol to another. So, while dealing with a pre-determined QC metrics threshold one should take it with a grain of salt.

**Mitigating the risk of pre-determined QC metrics threshold: using adaptive threshold**

Here we try to indentifies cells which are outlier to various QC metrics threshold based on median absolute deviation (MAD) from the median value of each metric across all cells. By default, we consider a value to be an outlier if it is more than 3 MADs from the median in the “problematic” direction (for example if we are looking at `sum` QC metrics then it means that if a cell has total `sum` count below 3 MADs, we consider it as an outlier). This is loosely motivated by the fact that such a filter will retain 99% of non-outlier values that follow a normal distribution.

We will use `perCellQCFilter()` from **scuttle** package.

```r
> reasons <- perCellQCFilters(df, 
+                             sub.fields=c("subsets_Mito_percent", 
+                                          "altexps_ERCC_percent"))
```
**explanation**

_reason_ is a DataFrame with one row per cell and containing columns of logical vectors. Each column specifies a reason for why a cell was considered to be low quality, with the final discard column indicating whether the cell should be discarded.

```r
> head(reasons)
DataFrame with 6 rows and 5 columns
      low_lib_size   low_n_features high_subsets_Mito_percent
  <outlier.filter> <outlier.filter>          <outlier.filter>
1            FALSE            FALSE                     FALSE
2            FALSE            FALSE                     FALSE
3            FALSE            FALSE                     FALSE
4            FALSE            FALSE                     FALSE
5            FALSE            FALSE                     FALSE
6            FALSE            FALSE                     FALSE
  high_altexps_ERCC_percent   discard
           <outlier.filter> <logical>
1                     FALSE     FALSE
2                     FALSE     FALSE
3                     FALSE     FALSE
4                     FALSE     FALSE
5                     FALSE     FALSE
6                     FALSE     FALSE
```

We can also look at the total number of cells discarded under each category

```r
> colSums(as.matrix(reasons))
             low_lib_size            low_n_features high_subsets_Mito_percent 
                        4                         0                         2 
high_altexps_ERCC_percent                   discard 
                        1                         6
```
                        
                        






  
  
  
